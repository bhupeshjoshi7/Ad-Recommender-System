{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Collection**\n",
    "The idea here is to gather my own data for classification. I am targeting data of videos available on Youtube. The data is collected for 6 categories:\n",
    "\n",
    "1. Travel Blogs\n",
    "2. Science and Technology\n",
    "3. Food\n",
    "4. Manufacturing\n",
    "5. History\n",
    "6. Art and Music\n",
    "\n",
    "To perform the required data collection, We have used the Youtube API v3. I decided to use the Youtube API since we need to collected >1700 samples, since it has an option to get data from subsequent pages of the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom apiclient.discovery import build\\nimport pandas as pd\\n\\n# Data to be stored\\ncategory = []\\nno_of_samples = 1700\\n\\n# Gathering Data using the Youtube API\\napi_key = \"AIzaSyAS9eTgOEnOJ2GlJbbqm_0bR1onuRQjTHE\"\\nyoutube_api = build(\\'youtube\\',\\'v3\\', developerKey = api_key)\\n\\n# Travel Data\\ntvl_titles = []\\ntvl_descriptions = []\\ntvl_ids = []\\n\\nreq = youtube_api.search().list(q=\\'travel vlogs\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(tvl_titles)<no_of_samples):\\n    for i in range(len(res[\\'items\\'])):\\n        tvl_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        tvl_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        tvl_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'travel\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n        req = youtube_api.search().list(q=\\'travelling\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    else:\\n        break\\n\\n\\n# Science Data\\nscience_titles = []\\nscience_descriptions = []\\nscience_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'robotics\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(science_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'robotics\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        science_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        science_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        science_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'science and technology\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n    \\n# Food Data\\nfood_titles = []\\nfood_descriptions = []\\nfood_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'delicious food\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(food_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'delicious food\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        food_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        food_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        food_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'food\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n\\n# Food Data\\nmanufacturing_titles = []\\nmanufacturing_descriptions = []\\nmanufacturing_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'3d printing\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(manufacturing_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'3d printing\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        manufacturing_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        manufacturing_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        manufacturing_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'manufacturing\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n    \\n# History Data\\nhistory_titles = []\\nhistory_descriptions = []\\nhistory_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'archaeology\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(history_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'archaeology\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        history_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        history_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        history_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'history\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n    \\n# Art and Music Data\\nart_titles = []\\nart_descriptions = []\\nart_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'painting\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(art_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'painting\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        art_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        art_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        art_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'art and music\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n \\n    \\n# Construct Dataset\\nfinal_titles = tvl_titles + science_titles + food_titles + manufacturing_titles + history_titles + art_titles\\nfinal_descriptions = tvl_descriptions + science_descriptions + food_descriptions + manufacturing_descriptions + history_descriptions + art_descriptions\\nfinal_ids = tvl_ids + science_ids + food_ids + manufacturing_ids + history_ids + art_ids\\ndata = pd.DataFrame({\\'Video Id\\': final_ids, \\'Title\\': final_titles, \\'Description\\': final_descriptions, \\'Category\\': category}) \\ndata.to_csv(\\'Videos_data.csv\\')\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from apiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "# Data to be stored\n",
    "category = []\n",
    "no_of_samples = 1700\n",
    "\n",
    "# Gathering Data using the Youtube API\n",
    "api_key = \"AIzaSyAS9eTgOEnOJ2GlJbbqm_0bR1onuRQjTHE\"\n",
    "youtube_api = build('youtube','v3', developerKey = api_key)\n",
    "\n",
    "# Travel Data\n",
    "tvl_titles = []\n",
    "tvl_descriptions = []\n",
    "tvl_ids = []\n",
    "\n",
    "req = youtube_api.search().list(q='travel vlogs', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(tvl_titles)<no_of_samples):\n",
    "    for i in range(len(res['items'])):\n",
    "        tvl_titles.append(res['items'][i]['snippet']['title'])\n",
    "        tvl_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        tvl_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('travel')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "        req = youtube_api.search().list(q='travelling', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "# Science Data\n",
    "science_titles = []\n",
    "science_descriptions = []\n",
    "science_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='robotics', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(science_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='robotics', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        science_titles.append(res['items'][i]['snippet']['title'])\n",
    "        science_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        science_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('science and technology')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# Food Data\n",
    "food_titles = []\n",
    "food_descriptions = []\n",
    "food_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='delicious food', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(food_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='delicious food', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        food_titles.append(res['items'][i]['snippet']['title'])\n",
    "        food_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        food_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('food')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Food Data\n",
    "manufacturing_titles = []\n",
    "manufacturing_descriptions = []\n",
    "manufacturing_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='3d printing', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(manufacturing_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='3d printing', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        manufacturing_titles.append(res['items'][i]['snippet']['title'])\n",
    "        manufacturing_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        manufacturing_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('manufacturing')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# History Data\n",
    "history_titles = []\n",
    "history_descriptions = []\n",
    "history_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='archaeology', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(history_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='archaeology', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        history_titles.append(res['items'][i]['snippet']['title'])\n",
    "        history_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        history_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('history')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# Art and Music Data\n",
    "art_titles = []\n",
    "art_descriptions = []\n",
    "art_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='painting', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(art_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='painting', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        art_titles.append(res['items'][i]['snippet']['title'])\n",
    "        art_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        art_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('art and music')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    " \n",
    "    \n",
    "# Construct Dataset\n",
    "final_titles = tvl_titles + science_titles + food_titles + manufacturing_titles + history_titles + art_titles\n",
    "final_descriptions = tvl_descriptions + science_descriptions + food_descriptions + manufacturing_descriptions + history_descriptions + art_descriptions\n",
    "final_ids = tvl_ids + science_ids + food_ids + manufacturing_ids + history_ids + art_ids\n",
    "data = pd.DataFrame({'Video Id': final_ids, 'Title': final_titles, 'Description': final_descriptions, 'Category': category}) \n",
    "data.to_csv('Videos_data.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (637005577.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install nltk\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install nltk \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bhupesh\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\bhupesh\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhupesh\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\bhupesh\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bhupesh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ehmsJLZlCZ0</td>\n",
       "      <td>Ep 1| Travelling through North East India | Of...</td>\n",
       "      <td>The journey to Arunachal, North East India beg...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2NQE41J5eM</td>\n",
       "      <td>How do I travel so much ! How do I earn money!!</td>\n",
       "      <td>SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i9E_Blai8vk</td>\n",
       "      <td>TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE</td>\n",
       "      <td>I had the chance to fly out to Bali with my wh...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...</td>\n",
       "      <td>Hope you enjoy MY GOA TRAVEL DIARY this video!...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ByoBJYXU0k</td>\n",
       "      <td>5 Steps to Becoming a Travel Blogger</td>\n",
       "      <td>Travel blogger, Nikki Vargas, of The Pin the M...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yvn79Rv0F48</td>\n",
       "      <td>Backpacking In Meghalaya | NorthEast India Tri...</td>\n",
       "      <td>In this video I explored North East India, sta...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SL_YBLWdZb8</td>\n",
       "      <td>Welcome to Peru! | Best Essential Tips &amp;amp; T...</td>\n",
       "      <td>Welcome to Peru! This essential travel guide w...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kiNyRY5s7n8</td>\n",
       "      <td>How to Start a Travel Blog [2019] Travel Blogg...</td>\n",
       "      <td>Create a Travel Blog Website for Just $3.95 + ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kY41XgTEEQU</td>\n",
       "      <td>A Day with KSRTC Bus Fans - Aanavandi Travel B...</td>\n",
       "      <td>ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7mIzRYh8jGA</td>\n",
       "      <td>What is it like to travel in PAKISTAN?</td>\n",
       "      <td>Subscribe now: https://goo.gl/6zXZGK Watch the...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video Id                                              Title  \\\n",
       "0  ehmsJLZlCZ0  Ep 1| Travelling through North East India | Of...   \n",
       "1  e2NQE41J5eM    How do I travel so much ! How do I earn money!!   \n",
       "2  i9E_Blai8vk      TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE   \n",
       "3       #NAME?  GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...   \n",
       "4  7ByoBJYXU0k               5 Steps to Becoming a Travel Blogger   \n",
       "5  yvn79Rv0F48  Backpacking In Meghalaya | NorthEast India Tri...   \n",
       "6  SL_YBLWdZb8  Welcome to Peru! | Best Essential Tips &amp; T...   \n",
       "7  kiNyRY5s7n8  How to Start a Travel Blog [2019] Travel Blogg...   \n",
       "8  kY41XgTEEQU  A Day with KSRTC Bus Fans - Aanavandi Travel B...   \n",
       "9  7mIzRYh8jGA             What is it like to travel in PAKISTAN?   \n",
       "\n",
       "                                         Description Category  \n",
       "0  The journey to Arunachal, North East India beg...   travel  \n",
       "1  SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...   travel  \n",
       "2  I had the chance to fly out to Bali with my wh...   travel  \n",
       "3  Hope you enjoy MY GOA TRAVEL DIARY this video!...   travel  \n",
       "4  Travel blogger, Nikki Vargas, of The Pin the M...   travel  \n",
       "5  In this video I explored North East India, sta...   travel  \n",
       "6  Welcome to Peru! This essential travel guide w...   travel  \n",
       "7  Create a Travel Blog Website for Just $3.95 + ...   travel  \n",
       "8  ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...   travel  \n",
       "9  Subscribe now: https://goo.gl/6zXZGK Watch the...   travel  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdata = pd.read_csv('Videos_data.csv')\n",
    "vdata = vdata.iloc[:, 1:]     # Remove extra un-named column\n",
    "vdata.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing and Cleaning**\n",
    "**Missing Values**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ehmsJLZlCZ0</td>\n",
       "      <td>ep  travelling through north east india  off t...</td>\n",
       "      <td>the journey to arunachal north east india begi...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2NQE41J5eM</td>\n",
       "      <td>how do i travel so much  how do i earn money</td>\n",
       "      <td>subscribe  httpsgoogldetsmj mountaintrekker gi...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i9E_Blai8vk</td>\n",
       "      <td>travel vlog ∙ welcome to bali  priscilla lee</td>\n",
       "      <td>i had the chance to fly out to bali with my wh...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>goa travel diary  four days in goa  travel out...</td>\n",
       "      <td>hope you enjoy my goa travel diary this video ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ByoBJYXU0k</td>\n",
       "      <td>steps to becoming a travel blogger</td>\n",
       "      <td>travel blogger nikki vargas of the pin the map...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>19jiwpTUGsY</td>\n",
       "      <td>watercolor scenery painting demo  rainy day</td>\n",
       "      <td>watercolor scenery painting demo  rainy day on...</td>\n",
       "      <td>art and music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>IMqrRwFf_20</td>\n",
       "      <td>speed painting blackstone fortress urghuls</td>\n",
       "      <td>music by midwinter minis enjoyed this series d...</td>\n",
       "      <td>art and music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>h96QOHz6i68</td>\n",
       "      <td>fabric painting step by step flowers painting ...</td>\n",
       "      <td>if you loved the video then please like share ...</td>\n",
       "      <td>art and music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10331</th>\n",
       "      <td>HyZfRPZZu5Y</td>\n",
       "      <td>the upside  quotdell unveils paintingquot clip...</td>\n",
       "      <td>the upside is director neil burgers heartfelt ...</td>\n",
       "      <td>art and music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>3ltZFbA2cfQ</td>\n",
       "      <td>speed painting blackstone fortress negavolt cu...</td>\n",
       "      <td>thanks to penny for stepping in to save the da...</td>\n",
       "      <td>art and music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Video Id                                              Title  \\\n",
       "0      ehmsJLZlCZ0  ep  travelling through north east india  off t...   \n",
       "1      e2NQE41J5eM       how do i travel so much  how do i earn money   \n",
       "2      i9E_Blai8vk       travel vlog ∙ welcome to bali  priscilla lee   \n",
       "3           #NAME?  goa travel diary  four days in goa  travel out...   \n",
       "4      7ByoBJYXU0k                 steps to becoming a travel blogger   \n",
       "...            ...                                                ...   \n",
       "10328  19jiwpTUGsY        watercolor scenery painting demo  rainy day   \n",
       "10329  IMqrRwFf_20         speed painting blackstone fortress urghuls   \n",
       "10330  h96QOHz6i68  fabric painting step by step flowers painting ...   \n",
       "10331  HyZfRPZZu5Y  the upside  quotdell unveils paintingquot clip...   \n",
       "10332  3ltZFbA2cfQ  speed painting blackstone fortress negavolt cu...   \n",
       "\n",
       "                                             Description       Category  \n",
       "0      the journey to arunachal north east india begi...         travel  \n",
       "1      subscribe  httpsgoogldetsmj mountaintrekker gi...         travel  \n",
       "2      i had the chance to fly out to bali with my wh...         travel  \n",
       "3      hope you enjoy my goa travel diary this video ...         travel  \n",
       "4      travel blogger nikki vargas of the pin the map...         travel  \n",
       "...                                                  ...            ...  \n",
       "10328  watercolor scenery painting demo  rainy day on...  art and music  \n",
       "10329  music by midwinter minis enjoyed this series d...  art and music  \n",
       "10330  if you loved the video then please like share ...  art and music  \n",
       "10331  the upside is director neil burgers heartfelt ...  art and music  \n",
       "10332  thanks to penny for stepping in to save the da...  art and music  \n",
       "\n",
       "[9999 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_desc = vdata.isnull().sum()[2]  \n",
    "# No. of values with msising descriptions\n",
    "print('Number of missing values: ' + str(num_missing_desc))\n",
    "vdata = vdata.dropna()\n",
    "vdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Cleaning\n",
    "The cleaning of the text is performed in the following manner:**\n",
    "\n",
    "\n",
    "1. Converting to Lowercase\n",
    "2. Removing numerical values, because they do not contribute towards predicting the category\n",
    "3. Removing Punctuation because special characters like $, !, etc. do not hold any useful information\n",
    "4. Removing extra white spaces\n",
    "5. Tokenizing into words - This means to convert a text string into a list of 'tokens', where each token is    word.\n",
    "6. Removing all non-alphabetic words\n",
    "7. Filtering out stop words such as and, the, is, etc. because they do not contain useful information for text classification\n",
    "8. Lemmatizing words - Lemmatizing reduces words to their base meaning, such as words 'fly' and 'flying' are both convert to just 'fly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bhupesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bhupesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bhupesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#  Change to lowercase\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mvdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m vdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Remove numbers\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:4397\u001b[0m, in \u001b[0;36mSeries.map\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[0;32m   4319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4320\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   4321\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4322\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4324\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[0;32m   4325\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4395\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   4396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4397\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4399\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4400\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\base.py:924\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mmap_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#  Change to lowercase\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m())\n\u001b[0;32m      3\u001b[0m vdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Remove numbers\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "#  Change to lowercase\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: x.lower())\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: x.lower())\n",
    "\n",
    "# Remove numbers\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: re.sub(r'\\d+', '', x))\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "# Remove Punctuation\n",
    "vdata['Title']  = vdata['Title'].map(lambda x: x.translate(x.maketrans('', '', string.punctuation)))\n",
    "vdata['Description']  = vdata['Description'].map(lambda x: x.translate(x.maketrans('', '', string.punctuation)))\n",
    "\n",
    "# Remove white spaces\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: x.strip())\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: x.strip())\n",
    "\n",
    "# Tokenize into words\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: word_tokenize(x))\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: word_tokenize(x))\n",
    " \n",
    "# Remove non alphabetic tokens\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: [word for word in x if word.isalpha()])\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "# filter out stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: [w for w in x if not w in stop_words])\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: [w for w in x if not w in stop_words])\n",
    "\n",
    "# Word Lemmatization\n",
    "lem = WordNetLemmatizer()\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: [lem.lemmatize(word,\"v\") for word in x])\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: [lem.lemmatize(word,\"v\") for word in x])\n",
    "\n",
    "# Turn lists back to string\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: ' '.join(x))\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ehmsJLZlCZ0</td>\n",
       "      <td>Ep 1| Travelling through North East India | Of...</td>\n",
       "      <td>The journey to Arunachal, North East India beg...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2NQE41J5eM</td>\n",
       "      <td>How do I travel so much ! How do I earn money!!</td>\n",
       "      <td>SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i9E_Blai8vk</td>\n",
       "      <td>TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE</td>\n",
       "      <td>I had the chance to fly out to Bali with my wh...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...</td>\n",
       "      <td>Hope you enjoy MY GOA TRAVEL DIARY this video!...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ByoBJYXU0k</td>\n",
       "      <td>5 Steps to Becoming a Travel Blogger</td>\n",
       "      <td>Travel blogger, Nikki Vargas, of The Pin the M...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yvn79Rv0F48</td>\n",
       "      <td>Backpacking In Meghalaya | NorthEast India Tri...</td>\n",
       "      <td>In this video I explored North East India, sta...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SL_YBLWdZb8</td>\n",
       "      <td>Welcome to Peru! | Best Essential Tips &amp;amp; T...</td>\n",
       "      <td>Welcome to Peru! This essential travel guide w...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kiNyRY5s7n8</td>\n",
       "      <td>How to Start a Travel Blog [2019] Travel Blogg...</td>\n",
       "      <td>Create a Travel Blog Website for Just $3.95 + ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kY41XgTEEQU</td>\n",
       "      <td>A Day with KSRTC Bus Fans - Aanavandi Travel B...</td>\n",
       "      <td>ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7mIzRYh8jGA</td>\n",
       "      <td>What is it like to travel in PAKISTAN?</td>\n",
       "      <td>Subscribe now: https://goo.gl/6zXZGK Watch the...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video Id                                              Title  \\\n",
       "0  ehmsJLZlCZ0  Ep 1| Travelling through North East India | Of...   \n",
       "1  e2NQE41J5eM    How do I travel so much ! How do I earn money!!   \n",
       "2  i9E_Blai8vk      TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE   \n",
       "3       #NAME?  GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...   \n",
       "4  7ByoBJYXU0k               5 Steps to Becoming a Travel Blogger   \n",
       "5  yvn79Rv0F48  Backpacking In Meghalaya | NorthEast India Tri...   \n",
       "6  SL_YBLWdZb8  Welcome to Peru! | Best Essential Tips &amp; T...   \n",
       "7  kiNyRY5s7n8  How to Start a Travel Blog [2019] Travel Blogg...   \n",
       "8  kY41XgTEEQU  A Day with KSRTC Bus Fans - Aanavandi Travel B...   \n",
       "9  7mIzRYh8jGA             What is it like to travel in PAKISTAN?   \n",
       "\n",
       "                                         Description Category  \n",
       "0  The journey to Arunachal, North East India beg...   travel  \n",
       "1  SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...   travel  \n",
       "2  I had the chance to fly out to Bali with my wh...   travel  \n",
       "3  Hope you enjoy MY GOA TRAVEL DIARY this video!...   travel  \n",
       "4  Travel blogger, Nikki Vargas, of The Pin the M...   travel  \n",
       "5  In this video I explored North East India, sta...   travel  \n",
       "6  Welcome to Peru! This essential travel guide w...   travel  \n",
       "7  Create a Travel Blog Website for Just $3.95 + ...   travel  \n",
       "8  ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...   travel  \n",
       "9  Subscribe now: https://goo.gl/6zXZGK Watch the...   travel  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Video Id       0\n",
       "Title          0\n",
       "Description    0\n",
       "Category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
