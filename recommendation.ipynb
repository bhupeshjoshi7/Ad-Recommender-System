{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Collection**\n",
    "The idea here is to gather my own data for classification. I am targeting data of videos available on Youtube. The data is collected for 6 categories:\n",
    "\n",
    "1. Travel Blogs\n",
    "2. Science and Technology\n",
    "3. Food\n",
    "4. Manufacturing\n",
    "5. History\n",
    "6. Art and Music\n",
    "\n",
    "To perform the required data collection, We have used the Youtube API v3. I decided to use the Youtube API since we need to collected >1700 samples, since it has an option to get data from subsequent pages of the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom apiclient.discovery import build\\nimport pandas as pd\\n\\n# Data to be stored\\ncategory = []\\nno_of_samples = 1700\\n\\n# Gathering Data using the Youtube API\\napi_key = \"AIzaSyAS9eTgOEnOJ2GlJbbqm_0bR1onuRQjTHE\"\\nyoutube_api = build(\\'youtube\\',\\'v3\\', developerKey = api_key)\\n\\n# Travel Data\\ntvl_titles = []\\ntvl_descriptions = []\\ntvl_ids = []\\n\\nreq = youtube_api.search().list(q=\\'travel vlogs\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(tvl_titles)<no_of_samples):\\n    for i in range(len(res[\\'items\\'])):\\n        tvl_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        tvl_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        tvl_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'travel\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n        req = youtube_api.search().list(q=\\'travelling\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    else:\\n        break\\n\\n\\n# Science Data\\nscience_titles = []\\nscience_descriptions = []\\nscience_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'robotics\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(science_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'robotics\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        science_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        science_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        science_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'science and technology\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n    \\n# Food Data\\nfood_titles = []\\nfood_descriptions = []\\nfood_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'delicious food\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(food_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'delicious food\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        food_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        food_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        food_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'food\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n\\n# Food Data\\nmanufacturing_titles = []\\nmanufacturing_descriptions = []\\nmanufacturing_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'3d printing\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(manufacturing_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'3d printing\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        manufacturing_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        manufacturing_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        manufacturing_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'manufacturing\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n    \\n# History Data\\nhistory_titles = []\\nhistory_descriptions = []\\nhistory_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'archaeology\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(history_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'archaeology\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        history_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        history_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        history_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'history\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n    \\n# Art and Music Data\\nart_titles = []\\nart_descriptions = []\\nart_ids = []\\n\\nnext_page_token = None\\nreq = youtube_api.search().list(q=\\'painting\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50)\\nres = req.execute()\\nwhile(len(art_titles)<no_of_samples):\\n    if(next_page_token is not None):\\n        req = youtube_api.search().list(q=\\'painting\\', part=\\'snippet\\', type=\\'video\\', maxResults = 50, pageToken=next_page_token)\\n        res = req.execute()\\n    for i in range(len(res[\\'items\\'])):\\n        art_titles.append(res[\\'items\\'][i][\\'snippet\\'][\\'title\\'])\\n        art_descriptions.append(res[\\'items\\'][i][\\'snippet\\'][\\'description\\'])\\n        art_ids.append(res[\\'items\\'][i][\\'id\\'][\\'videoId\\'])\\n        category.append(\\'art and music\\')\\n            \\n    if(\\'nextPageToken\\' in res):\\n        next_page_token = res[\\'nextPageToken\\']\\n    else:\\n        break\\n \\n    \\n# Construct Dataset\\nfinal_titles = tvl_titles + science_titles + food_titles + manufacturing_titles + history_titles + art_titles\\nfinal_descriptions = tvl_descriptions + science_descriptions + food_descriptions + manufacturing_descriptions + history_descriptions + art_descriptions\\nfinal_ids = tvl_ids + science_ids + food_ids + manufacturing_ids + history_ids + art_ids\\ndata = pd.DataFrame({\\'Video Id\\': final_ids, \\'Title\\': final_titles, \\'Description\\': final_descriptions, \\'Category\\': category}) \\ndata.to_csv(\\'Videos_data.csv\\')\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from apiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "# Data to be stored\n",
    "category = []\n",
    "no_of_samples = 1700\n",
    "\n",
    "# Gathering Data using the Youtube API\n",
    "api_key = \"AIzaSyAS9eTgOEnOJ2GlJbbqm_0bR1onuRQjTHE\"\n",
    "youtube_api = build('youtube','v3', developerKey = api_key)\n",
    "\n",
    "# Travel Data\n",
    "tvl_titles = []\n",
    "tvl_descriptions = []\n",
    "tvl_ids = []\n",
    "\n",
    "req = youtube_api.search().list(q='travel vlogs', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(tvl_titles)<no_of_samples):\n",
    "    for i in range(len(res['items'])):\n",
    "        tvl_titles.append(res['items'][i]['snippet']['title'])\n",
    "        tvl_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        tvl_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('travel')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "        req = youtube_api.search().list(q='travelling', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "# Science Data\n",
    "science_titles = []\n",
    "science_descriptions = []\n",
    "science_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='robotics', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(science_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='robotics', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        science_titles.append(res['items'][i]['snippet']['title'])\n",
    "        science_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        science_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('science and technology')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# Food Data\n",
    "food_titles = []\n",
    "food_descriptions = []\n",
    "food_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='delicious food', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(food_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='delicious food', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        food_titles.append(res['items'][i]['snippet']['title'])\n",
    "        food_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        food_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('food')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Food Data\n",
    "manufacturing_titles = []\n",
    "manufacturing_descriptions = []\n",
    "manufacturing_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='3d printing', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(manufacturing_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='3d printing', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        manufacturing_titles.append(res['items'][i]['snippet']['title'])\n",
    "        manufacturing_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        manufacturing_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('manufacturing')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# History Data\n",
    "history_titles = []\n",
    "history_descriptions = []\n",
    "history_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='archaeology', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(history_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='archaeology', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        history_titles.append(res['items'][i]['snippet']['title'])\n",
    "        history_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        history_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('history')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# Art and Music Data\n",
    "art_titles = []\n",
    "art_descriptions = []\n",
    "art_ids = []\n",
    "\n",
    "next_page_token = None\n",
    "req = youtube_api.search().list(q='painting', part='snippet', type='video', maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(art_titles)<no_of_samples):\n",
    "    if(next_page_token is not None):\n",
    "        req = youtube_api.search().list(q='painting', part='snippet', type='video', maxResults = 50, pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    for i in range(len(res['items'])):\n",
    "        art_titles.append(res['items'][i]['snippet']['title'])\n",
    "        art_descriptions.append(res['items'][i]['snippet']['description'])\n",
    "        art_ids.append(res['items'][i]['id']['videoId'])\n",
    "        category.append('art and music')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "    else:\n",
    "        break\n",
    " \n",
    "    \n",
    "# Construct Dataset\n",
    "final_titles = tvl_titles + science_titles + food_titles + manufacturing_titles + history_titles + art_titles\n",
    "final_descriptions = tvl_descriptions + science_descriptions + food_descriptions + manufacturing_descriptions + history_descriptions + art_descriptions\n",
    "final_ids = tvl_ids + science_ids + food_ids + manufacturing_ids + history_ids + art_ids\n",
    "data = pd.DataFrame({'Video Id': final_ids, 'Title': final_titles, 'Description': final_descriptions, 'Category': category}) \n",
    "data.to_csv('Videos_data.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ep 1| Travelling through North East India | Of...</td>\n",
       "      <td>The journey to Arunachal, North East India beg...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I travel so much ! How do I earn money!!</td>\n",
       "      <td>SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE</td>\n",
       "      <td>I had the chance to fly out to Bali with my wh...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...</td>\n",
       "      <td>Hope you enjoy MY GOA TRAVEL DIARY this video!...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Steps to Becoming a Travel Blogger</td>\n",
       "      <td>Travel blogger, Nikki Vargas, of The Pin the M...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Backpacking In Meghalaya | NorthEast India Tri...</td>\n",
       "      <td>In this video I explored North East India, sta...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Welcome to Peru! | Best Essential Tips &amp;amp; T...</td>\n",
       "      <td>Welcome to Peru! This essential travel guide w...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How to Start a Travel Blog [2019] Travel Blogg...</td>\n",
       "      <td>Create a Travel Blog Website for Just $3.95 + ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A Day with KSRTC Bus Fans - Aanavandi Travel B...</td>\n",
       "      <td>ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is it like to travel in PAKISTAN?</td>\n",
       "      <td>Subscribe now: https://goo.gl/6zXZGK Watch the...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Ep 1| Travelling through North East India | Of...   \n",
       "1    How do I travel so much ! How do I earn money!!   \n",
       "2      TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE   \n",
       "3  GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...   \n",
       "4               5 Steps to Becoming a Travel Blogger   \n",
       "5  Backpacking In Meghalaya | NorthEast India Tri...   \n",
       "6  Welcome to Peru! | Best Essential Tips &amp; T...   \n",
       "7  How to Start a Travel Blog [2019] Travel Blogg...   \n",
       "8  A Day with KSRTC Bus Fans - Aanavandi Travel B...   \n",
       "9             What is it like to travel in PAKISTAN?   \n",
       "\n",
       "                                         Description Category  \n",
       "0  The journey to Arunachal, North East India beg...   travel  \n",
       "1  SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...   travel  \n",
       "2  I had the chance to fly out to Bali with my wh...   travel  \n",
       "3  Hope you enjoy MY GOA TRAVEL DIARY this video!...   travel  \n",
       "4  Travel blogger, Nikki Vargas, of The Pin the M...   travel  \n",
       "5  In this video I explored North East India, sta...   travel  \n",
       "6  Welcome to Peru! This essential travel guide w...   travel  \n",
       "7  Create a Travel Blog Website for Just $3.95 + ...   travel  \n",
       "8  ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...   travel  \n",
       "9  Subscribe now: https://goo.gl/6zXZGK Watch the...   travel  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdata = pd.read_csv('Videos_data.csv')\n",
    "vdata = data.iloc[:, 1:]     # Remove extra un-named column\n",
    "vdata.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing and Cleaning**\n",
    "**Missing Values**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "num_missing_desc = data.isnull().sum()[2]  \n",
    "# No. of values with msising descriptions\n",
    "print('Number of missing values: ' + str(num_missing_desc))\n",
    "vdata = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Cleaning\n",
    "The cleaning of the text is performed in the following manner:**\n",
    "\n",
    "\n",
    "1. Converting to Lowercase\n",
    "2. Removing numerical values, because they do not contribute towards predicting the category\n",
    "3. Removing Punctuation because special characters like $, !, etc. do not hold any useful information\n",
    "4. Removing extra white spaces\n",
    "5. Tokenizing into words - This means to convert a text string into a list of 'tokens', where each token is    word.\n",
    "6. Removing all non-alphabetic words\n",
    "7. Filtering out stop words such as and, the, is, etc. because they do not contain useful information for text classification\n",
    "8. Lemmatizing words - Lemmatizing reduces words to their base meaning, such as words 'fly' and 'flying' are both convert to just 'fly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Change to lowercase\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: x.lower())\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: x.lower())\n",
    "\n",
    "# Remove numbers\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: re.sub(r'\\d+', '', x))\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "# Remove Punctuation\n",
    "vdata['Title']  = vdata['Title'].map(lambda x: x.translate(x.maketrans('', '', string.punctuation)))\n",
    "vdata['Description']  = vdata['Description'].map(lambda x: x.translate(x.maketrans('', '', string.punctuation)))\n",
    "\n",
    "# Remove white spaces\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: x.strip())\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: x.strip())\n",
    "\n",
    "# Tokenize into words\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: word_tokenize(x))\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: word_tokenize(x))\n",
    " \n",
    "# Remove non alphabetic tokens\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: [word for word in x if word.isalpha()])\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "# filter out stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: [w for w in x if not w in stop_words])\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: [w for w in x if not w in stop_words])\n",
    "\n",
    "# Word Lemmatization\n",
    "lem = WordNetLemmatizer()\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: [lem.lemmatize(word,\"v\") for word in x])\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: [lem.lemmatize(word,\"v\") for word in x])\n",
    "\n",
    "# Turn lists back to string\n",
    "vdata['Title'] = vdata['Title'].map(lambda x: ' '.join(x))\n",
    "vdata['Description'] = vdata['Description'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ehmsJLZlCZ0</td>\n",
       "      <td>Ep 1| Travelling through North East India | Of...</td>\n",
       "      <td>The journey to Arunachal, North East India beg...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2NQE41J5eM</td>\n",
       "      <td>How do I travel so much ! How do I earn money!!</td>\n",
       "      <td>SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i9E_Blai8vk</td>\n",
       "      <td>TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE</td>\n",
       "      <td>I had the chance to fly out to Bali with my wh...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...</td>\n",
       "      <td>Hope you enjoy MY GOA TRAVEL DIARY this video!...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ByoBJYXU0k</td>\n",
       "      <td>5 Steps to Becoming a Travel Blogger</td>\n",
       "      <td>Travel blogger, Nikki Vargas, of The Pin the M...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yvn79Rv0F48</td>\n",
       "      <td>Backpacking In Meghalaya | NorthEast India Tri...</td>\n",
       "      <td>In this video I explored North East India, sta...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SL_YBLWdZb8</td>\n",
       "      <td>Welcome to Peru! | Best Essential Tips &amp;amp; T...</td>\n",
       "      <td>Welcome to Peru! This essential travel guide w...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kiNyRY5s7n8</td>\n",
       "      <td>How to Start a Travel Blog [2019] Travel Blogg...</td>\n",
       "      <td>Create a Travel Blog Website for Just $3.95 + ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kY41XgTEEQU</td>\n",
       "      <td>A Day with KSRTC Bus Fans - Aanavandi Travel B...</td>\n",
       "      <td>ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7mIzRYh8jGA</td>\n",
       "      <td>What is it like to travel in PAKISTAN?</td>\n",
       "      <td>Subscribe now: https://goo.gl/6zXZGK Watch the...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video Id                                              Title  \\\n",
       "0  ehmsJLZlCZ0  Ep 1| Travelling through North East India | Of...   \n",
       "1  e2NQE41J5eM    How do I travel so much ! How do I earn money!!   \n",
       "2  i9E_Blai8vk      TRAVEL VLOG ∙ Welcome to Bali | PRISCILLA LEE   \n",
       "3       #NAME?  GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...   \n",
       "4  7ByoBJYXU0k               5 Steps to Becoming a Travel Blogger   \n",
       "5  yvn79Rv0F48  Backpacking In Meghalaya | NorthEast India Tri...   \n",
       "6  SL_YBLWdZb8  Welcome to Peru! | Best Essential Tips &amp; T...   \n",
       "7  kiNyRY5s7n8  How to Start a Travel Blog [2019] Travel Blogg...   \n",
       "8  kY41XgTEEQU  A Day with KSRTC Bus Fans - Aanavandi Travel B...   \n",
       "9  7mIzRYh8jGA             What is it like to travel in PAKISTAN?   \n",
       "\n",
       "                                         Description Category  \n",
       "0  The journey to Arunachal, North East India beg...   travel  \n",
       "1  SUBSCRIBE - https://goo.gl/dEtSMJ ('MountainTr...   travel  \n",
       "2  I had the chance to fly out to Bali with my wh...   travel  \n",
       "3  Hope you enjoy MY GOA TRAVEL DIARY this video!...   travel  \n",
       "4  Travel blogger, Nikki Vargas, of The Pin the M...   travel  \n",
       "5  In this video I explored North East India, sta...   travel  \n",
       "6  Welcome to Peru! This essential travel guide w...   travel  \n",
       "7  Create a Travel Blog Website for Just $3.95 + ...   travel  \n",
       "8  ആനവണ്ടി ഭ്രാന്തൻമാരോടൊപ്പം കുമളിയിൽ ഒരു ദിവസം ...   travel  \n",
       "9  Subscribe now: https://goo.gl/6zXZGK Watch the...   travel  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Video Id       0\n",
       "Title          0\n",
       "Description    0\n",
       "Category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is  my change\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
